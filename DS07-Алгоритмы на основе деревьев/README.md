# Алгоритмы на основе деревьев

### Task 1
Датасет - [заявки на кредит](datasets/credit_scoring.csv). 
Найдём имена клиентов, которым должны одобрить заявку на кредит, исходя из следующего:

- клиенту не менее 18 лет;
- месячный доход привышает 10000 рублей


### Task 2
Задача классификации \
Датасет - [классификация ирисов](https://scikit-learn.org/stable/datasets/toy_dataset.html#iris-plants-dataset) с измерениями параметров чашелистиков и лепестков для различных видов ирисов. 
Отобразим диаграмму рассеяний *Scatterplot*, по оси `x` - **Длина чашелистика**, по оси `y` - **Длина лепестка** 

### Task 3
Решим эту же задачу классификации подвидов ирисов с помощью деревьев решений \
Разделим датасет на обучающую и тестовую выборки \
Обучим дерево решений с глубиной - 2, по признакам **Длина чашелистика** и **Длина лепестка** и посчитаем точность классификации `accuracy`

### Task 4
Отрисуем [разделяющии поверхности](code-samples/surface.py) по признакам **Длина чашелистика** и **Длина лепестка** и нарисуем дерево решений \
Выведем количество листов у дерева решений

### Task 5
Решим задачу регрессии с помощью деревьев решений \
Отрисуем [синусоидальный сигнал](code-samples/dataset.py) с небольшими шумами размером 1000 отсчетов \
Разделим датасет на обучающую и тестовую выборки, обучи дерево решений c глубиной - 1 \
Построим график по признакам **Длина чашелистика** и **Длина лепестка** для истинных ответов и предсказаний модели и нарисуем дерево решений

### Task 6
Меняя грубину дерева от 1 до 30, построим график зависимости среднеквадратичная ошибка *MSE* предсказаний на тестовой выборке от **Глубины дерева** \
Выведем глубину дерева с наилучшим качеством модели 

### Task 7
Теперь используем метод *BaggingRegressor* из модуля *sklearn.ensemble* для обучения ансамбля несколькольких деревьев решений и построим график зависимости среднеквадратичная ошибка *MSE* от **Количества базовых моделей**, меняя количество моделей от 1 до 50 \
Выведем количество моделей с наилучшим качеством модели

### Task 8
Алгоритмом случайного леса *Random Forest* \
Обучим алгоритм случайного леса и посчитаем среднеквадратичную ошибку MSE на тестовой выборке
